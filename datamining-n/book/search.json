[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Mining in Python",
    "section": "",
    "text": "About the author\n\nWitek ten Hove is a senior instructor and researcher at HAN University of Applied Sciences. His main areas of expertise are Data en Web Technologies.\nThrough his extensive business experience in Finance and International Trade and thorough knowledge of modern data technologies, he is able to make connections between technology and business. As an open source evangelist he firmly believe in the power of knowledge sharing. His mission is to inspire business professionals and help them exploit the full potential of smart technologies.\nHe is the owner of Ten Hove Business Data Solutions, a consultancy and training company helping organizations to achieve maximum business value through data driven solutions."
  },
  {
    "objectID": "setup.html#working-with-git-and-github",
    "href": "setup.html#working-with-git-and-github",
    "title": "1  Setting up your data science environment",
    "section": "1.2 Working with Git and Github",
    "text": "1.2 Working with Git and Github"
  },
  {
    "objectID": "setup.html#using-python-virtual-environments",
    "href": "setup.html#using-python-virtual-environments",
    "title": "1  Setting up your data science environment",
    "section": "1.3 Using Python virtual environments",
    "text": "1.3 Using Python virtual environments"
  },
  {
    "objectID": "knn.html#business-case-diagnosing-breast-cancer",
    "href": "knn.html#business-case-diagnosing-breast-cancer",
    "title": "2  Lazy learning with k-Nearest Neighbors",
    "section": "2.1 Business Case: Diagnosing Breast Cancer",
    "text": "2.1 Business Case: Diagnosing Breast Cancer\nBreast cancer is the top cancer in women both in the developed and the developing world. In the Netherlands it is the most pervasive form of cancer (“WHO  Cancer Country Profiles 2020” n.d.). In order to improve breast cancer outcome and survival early detection remains the most important instrument for breast cancer control. If machine learning could automate the identification of cancer, it would improve efficiency of the detection process and might also increase its effectiveness by providing greater detection accuracy."
  },
  {
    "objectID": "knn.html#data-understanding",
    "href": "knn.html#data-understanding",
    "title": "2  Lazy learning with k-Nearest Neighbors",
    "section": "2.2 Data Understanding",
    "text": "2.2 Data Understanding\nThe data we will be using comes from the University of Wisconsin and is available online as an open source dataset (“UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set” n.d.). It includes measurements from digitized images from from fine-needle aspirates of breast mass. The values represent cell nuclei features.\nFor convenience the data in csv format is stored on Github. We can access it directly using a function dedicated to reading csv from the readr package.\n\nurl <- \"https://raw.githubusercontent.com/businessdatasolutions/courses/main/data%20mining/gitbook/datasets/breastcancer.csv\"\nrawDF <- read_csv(url)\n\nUsing the str() function we can have some basic information about the dataset.\n\nstr(rawDF)\n\nspec_tbl_df [569 × 32] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id               : num [1:569] 87139402 8910251 905520 868871 9012568 ...\n $ diagnosis        : chr [1:569] \"B\" \"B\" \"B\" \"B\" ...\n $ radius_mean      : num [1:569] 12.3 10.6 11 11.3 15.2 ...\n $ texture_mean     : num [1:569] 12.4 18.9 16.8 13.4 13.2 ...\n $ perimeter_mean   : num [1:569] 78.8 69.3 70.9 73 97.7 ...\n $ area_mean        : num [1:569] 464 346 373 385 712 ...\n $ smoothness_mean  : num [1:569] 0.1028 0.0969 0.1077 0.1164 0.0796 ...\n $ compactness_mean : num [1:569] 0.0698 0.1147 0.078 0.1136 0.0693 ...\n $ concavity_mean   : num [1:569] 0.0399 0.0639 0.0305 0.0464 0.0339 ...\n $ points_mean      : num [1:569] 0.037 0.0264 0.0248 0.048 0.0266 ...\n $ symmetry_mean    : num [1:569] 0.196 0.192 0.171 0.177 0.172 ...\n $ dimension_mean   : num [1:569] 0.0595 0.0649 0.0634 0.0607 0.0554 ...\n $ radius_se        : num [1:569] 0.236 0.451 0.197 0.338 0.178 ...\n $ texture_se       : num [1:569] 0.666 1.197 1.387 1.343 0.412 ...\n $ perimeter_se     : num [1:569] 1.67 3.43 1.34 1.85 1.34 ...\n $ area_se          : num [1:569] 17.4 27.1 13.5 26.3 17.7 ...\n $ smoothness_se    : num [1:569] 0.00805 0.00747 0.00516 0.01127 0.00501 ...\n $ compactness_se   : num [1:569] 0.0118 0.03581 0.00936 0.03498 0.01485 ...\n $ concavity_se     : num [1:569] 0.0168 0.0335 0.0106 0.0219 0.0155 ...\n $ points_se        : num [1:569] 0.01241 0.01365 0.00748 0.01965 0.00915 ...\n $ symmetry_se      : num [1:569] 0.0192 0.035 0.0172 0.0158 0.0165 ...\n $ dimension_se     : num [1:569] 0.00225 0.00332 0.0022 0.00344 0.00177 ...\n $ radius_worst     : num [1:569] 13.5 11.9 12.4 11.9 16.2 ...\n $ texture_worst    : num [1:569] 15.6 22.9 26.4 15.8 15.7 ...\n $ perimeter_worst  : num [1:569] 87 78.3 79.9 76.5 104.5 ...\n $ area_worst       : num [1:569] 549 425 471 434 819 ...\n $ smoothness_worst : num [1:569] 0.139 0.121 0.137 0.137 0.113 ...\n $ compactness_worst: num [1:569] 0.127 0.252 0.148 0.182 0.174 ...\n $ concavity_worst  : num [1:569] 0.1242 0.1916 0.1067 0.0867 0.1362 ...\n $ points_worst     : num [1:569] 0.0939 0.0793 0.0743 0.0861 0.0818 ...\n $ symmetry_worst   : num [1:569] 0.283 0.294 0.3 0.21 0.249 ...\n $ dimension_worst  : num [1:569] 0.0677 0.0759 0.0788 0.0678 0.0677 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   diagnosis = col_character(),\n  ..   radius_mean = col_double(),\n  ..   texture_mean = col_double(),\n  ..   perimeter_mean = col_double(),\n  ..   area_mean = col_double(),\n  ..   smoothness_mean = col_double(),\n  ..   compactness_mean = col_double(),\n  ..   concavity_mean = col_double(),\n  ..   points_mean = col_double(),\n  ..   symmetry_mean = col_double(),\n  ..   dimension_mean = col_double(),\n  ..   radius_se = col_double(),\n  ..   texture_se = col_double(),\n  ..   perimeter_se = col_double(),\n  ..   area_se = col_double(),\n  ..   smoothness_se = col_double(),\n  ..   compactness_se = col_double(),\n  ..   concavity_se = col_double(),\n  ..   points_se = col_double(),\n  ..   symmetry_se = col_double(),\n  ..   dimension_se = col_double(),\n  ..   radius_worst = col_double(),\n  ..   texture_worst = col_double(),\n  ..   perimeter_worst = col_double(),\n  ..   area_worst = col_double(),\n  ..   smoothness_worst = col_double(),\n  ..   compactness_worst = col_double(),\n  ..   concavity_worst = col_double(),\n  ..   points_worst = col_double(),\n  ..   symmetry_worst = col_double(),\n  ..   dimension_worst = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nThe dataset has 32 variables (columns) and 569 observations (rows)."
  },
  {
    "objectID": "knn.html#preparation",
    "href": "knn.html#preparation",
    "title": "2  Lazy learning with k-Nearest Neighbors",
    "section": "2.3 Preparation",
    "text": "2.3 Preparation\nThe first variable, id, contains unique patient IDs. The IDs do not contain any relevant information for making predictions, so we will delete it from the dataset.\n\ncleanDF <- rawDF[-1]\nhead(cleanDF)\n\n# A tibble: 6 × 31\n  diagnosis radius_mean textur…¹ perim…² area_…³ smoot…⁴ compa…⁵ conca…⁶ point…⁷\n  <chr>           <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 B                12.3     12.4    78.8    464.  0.103   0.0698  0.0399  0.037 \n2 B                10.6     19.0    69.3    346.  0.0969  0.115   0.0639  0.0264\n3 B                11.0     16.8    70.9    373.  0.108   0.0780  0.0305  0.0248\n4 B                11.3     13.4    73      385.  0.116   0.114   0.0464  0.0480\n5 B                15.2     13.2    97.6    712.  0.0796  0.0693  0.0339  0.0266\n6 B                11.6     19.0    74.2    410.  0.0855  0.0772  0.0548  0.0143\n# … with 22 more variables: symmetry_mean <dbl>, dimension_mean <dbl>,\n#   radius_se <dbl>, texture_se <dbl>, perimeter_se <dbl>, area_se <dbl>,\n#   smoothness_se <dbl>, compactness_se <dbl>, concavity_se <dbl>,\n#   points_se <dbl>, symmetry_se <dbl>, dimension_se <dbl>, radius_worst <dbl>,\n#   texture_worst <dbl>, perimeter_worst <dbl>, area_worst <dbl>,\n#   smoothness_worst <dbl>, compactness_worst <dbl>, concavity_worst <dbl>,\n#   points_worst <dbl>, symmetry_worst <dbl>, dimension_worst <dbl>, and …\n# ℹ Use `colnames()` to see all variable names\n\n\nThe variable named diagnosis contains the outcomes we would like to predict - ‘B’ for ‘Benign’ and ‘M’ for ‘Malignant’. The variable we would like to predict is called the ‘label’. We can look at the counts and proportions for both outcomes, using the tables() and prop.tables()functions.\n\ncntDiag <- table(cleanDF$diagnosis)\npropDiag <- round(prop.table(cntDiag) * 100 , digits = 1)\n\ncntDiag\n\n\n  B   M \n357 212 \n\npropDiag\n\n\n   B    M \n62.7 37.3 \n\n\nThe variable is now coded as a type character. Many models require that the label is of type factor. This is easily solved using the factor() function.\n\ncleanDF$diagnosis <- factor(cleanDF$diagnosis, levels = c(\"B\", \"M\"), labels = c(\"Benign\", \"Malignant\")) %>% relevel(\"Malignant\")\nhead(cleanDF, 10)\n\n# A tibble: 10 × 31\n   diagnosis radius_mean textu…¹ perim…² area_…³ smoot…⁴ compa…⁵ conca…⁶ point…⁷\n   <fct>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Benign           12.3    12.4    78.8    464.  0.103   0.0698  0.0399  0.037 \n 2 Benign           10.6    19.0    69.3    346.  0.0969  0.115   0.0639  0.0264\n 3 Benign           11.0    16.8    70.9    373.  0.108   0.0780  0.0305  0.0248\n 4 Benign           11.3    13.4    73      385.  0.116   0.114   0.0464  0.0480\n 5 Benign           15.2    13.2    97.6    712.  0.0796  0.0693  0.0339  0.0266\n 6 Benign           11.6    19.0    74.2    410.  0.0855  0.0772  0.0548  0.0143\n 7 Benign           11.5    23.9    74.5    404.  0.0926  0.102   0.111   0.0411\n 8 Malignant        13.8    23.8    91.6    598.  0.132   0.177   0.156   0.0918\n 9 Benign           10.5    19.3    67.4    336.  0.0999  0.0858  0.0300  0.0120\n10 Benign           11.1    15.0    71.5    374.  0.103   0.0910  0.0540  0.0334\n# … with 22 more variables: symmetry_mean <dbl>, dimension_mean <dbl>,\n#   radius_se <dbl>, texture_se <dbl>, perimeter_se <dbl>, area_se <dbl>,\n#   smoothness_se <dbl>, compactness_se <dbl>, concavity_se <dbl>,\n#   points_se <dbl>, symmetry_se <dbl>, dimension_se <dbl>, radius_worst <dbl>,\n#   texture_worst <dbl>, perimeter_worst <dbl>, area_worst <dbl>,\n#   smoothness_worst <dbl>, compactness_worst <dbl>, concavity_worst <dbl>,\n#   points_worst <dbl>, symmetry_worst <dbl>, dimension_worst <dbl>, and …\n# ℹ Use `colnames()` to see all variable names\n\n\nThe features consist of three different measurements of ten characteristics. We will take three characteristics and have a closer look.\n\nsummary(cleanDF[c(\"radius_mean\", \"area_mean\", \"smoothness_mean\")])\n\n  radius_mean       area_mean      smoothness_mean  \n Min.   : 6.981   Min.   : 143.5   Min.   :0.05263  \n 1st Qu.:11.700   1st Qu.: 420.3   1st Qu.:0.08637  \n Median :13.370   Median : 551.1   Median :0.09587  \n Mean   :14.127   Mean   : 654.9   Mean   :0.09636  \n 3rd Qu.:15.780   3rd Qu.: 782.7   3rd Qu.:0.10530  \n Max.   :28.110   Max.   :2501.0   Max.   :0.16340  \n\n\nYou’ll notice that the three variables have very different ranges and as a consequence area_mean will have a larger impact on the distance calculation than the smootness_mean. This could potentially cause problems for modeling. To solve this we’ll apply normalization to rescale all features to a standard range of values.\nWe will write our own normalization function.\n\nnormalize <- function(x) { # Function takes in a vector\n  return ((x - min(x)) / (max(x) - min(x))) # distance of item value - minimum vector value divided by the range of all vector values\n}\n\ntestSet1 <- c(1:5)\ntestSet2 <- c(1:5) * 10\n\ncat(\"testSet1:\", testSet1, \"\\n\")\n\ntestSet1: 1 2 3 4 5 \n\ncat(\"testSet2:\", testSet2, \"\\n\")\n\ntestSet2: 10 20 30 40 50 \n\ncat(\"Normalized testSet1:\", normalize(testSet1), \"\\n\")\n\nNormalized testSet1: 0 0.25 0.5 0.75 1 \n\ncat(\"Normalized testSet2:\", normalize(testSet2))\n\nNormalized testSet2: 0 0.25 0.5 0.75 1\n\n\nWe’ll apply the normalize() function to each feature in the dataset (so, not on the label) using the sapply() function.\n\nnCols <- dim(cleanDF)[2]\ncleanDF_n <- sapply(2:nCols,\n                    function(x) {\n  normalize(cleanDF[,x])\n}) %>% as.data.frame()\n\nsummary(cleanDF_n[c(\"radius_mean\", \"area_mean\", \"smoothness_mean\")])\n\n  radius_mean       area_mean      smoothness_mean \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2233   1st Qu.:0.1174   1st Qu.:0.3046  \n Median :0.3024   Median :0.1729   Median :0.3904  \n Mean   :0.3382   Mean   :0.2169   Mean   :0.3948  \n 3rd Qu.:0.4164   3rd Qu.:0.2711   3rd Qu.:0.4755  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\nWhen we take the variables we selected earlier and look at the summary parameters again, we’ll see that the normalization was successful.\nWe can now split our data into training and test sets.\n\ntrainDF_feat <- cleanDF_n[1:469,  ]\ntestDF_feat <- cleanDF_n[470:569,  ]\n\nWhen creating the training and test sets, we’ve excluded the labels. We’ll create separate training and tests sets for them too.\n\ntrainDF_labels <- cleanDF[1:469,  1]\ntestDF_labels <- cleanDF[470:569,  1]\n\nNow we can train and evaluate our kNN model."
  },
  {
    "objectID": "knn.html#modeling-and-evaluation",
    "href": "knn.html#modeling-and-evaluation",
    "title": "2  Lazy learning with k-Nearest Neighbors",
    "section": "2.4 Modeling and Evaluation",
    "text": "2.4 Modeling and Evaluation\nTo train the knn model we only need one single function from the class package. It takes the set with training features and the set with training label. The trained model is applied to the set with test features and the function gives back a set of predictions.\n\ncleanDF_test_pred <- knn(train = as.matrix(trainDF_feat), test = as.matrix(testDF_feat), cl = as.matrix(trainDF_labels), k = 21)\nhead(cleanDF_test_pred)\n\n[1] Benign    Benign    Benign    Benign    Malignant Benign   \nLevels: Benign Malignant\n\n\nNow that we have a set of predicted labels we can compare these with the actual labels. A diffusion table shows how well the model performed.\n\n\n\n\n\nStandard diffusion table. Taken from: https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg\n\n\n\n\nHere is our own table:\n\nconfusionMatrix(cleanDF_test_pred, testDF_labels[[1]], positive = NULL, dnn = c(\"Prediction\", \"True\"))\n\nWarning in confusionMatrix.default(cleanDF_test_pred, testDF_labels[[1]], :\nLevels are not in the same order for reference and data. Refactoring data to\nmatch.\n\n\nConfusion Matrix and Statistics\n\n           True\nPrediction  Malignant Benign\n  Malignant        37      0\n  Benign            2     61\n                                          \n               Accuracy : 0.98            \n                 95% CI : (0.9296, 0.9976)\n    No Information Rate : 0.61            \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.9576          \n                                          \n Mcnemar's Test P-Value : 0.4795          \n                                          \n            Sensitivity : 0.9487          \n            Specificity : 1.0000          \n         Pos Pred Value : 1.0000          \n         Neg Pred Value : 0.9683          \n             Prevalence : 0.3900          \n         Detection Rate : 0.3700          \n   Detection Prevalence : 0.3700          \n      Balanced Accuracy : 0.9744          \n                                          \n       'Positive' Class : Malignant       \n                                          \n\n\nQuestions:\n\nHow would you assess the overall performance of the model?\nWhat would you consider as more costly: high false negatives or high false positives levels? Why?\n\n\n\n\n\n“UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set.” n.d. Accessed January 7, 2021. https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic).\n\n\n“WHO  Cancer Country Profiles 2020.” n.d. WHO. Accessed January 7, 2021. http://www.who.int/cancer/country-profiles/en/."
  },
  {
    "objectID": "nb.html#business-case-filtering-spam",
    "href": "nb.html#business-case-filtering-spam",
    "title": "3  Probabilistic Learning with Naive Bayes Classification",
    "section": "3.1 Business Case: Filtering Spam",
    "text": "3.1 Business Case: Filtering Spam\nIn 2020 spam accounted for more than 50% of total e-mail traffic (“Spam Statistics: Spam e-Mail Traffic Share 2019” n.d.). This illustrates the value of a good spam filter. Naive Bayes spam filtering is a standard technique for handling spam. It is one of the oldest ways of doing spam filtering, with roots in the 1990s."
  },
  {
    "objectID": "nb.html#data-understanding",
    "href": "nb.html#data-understanding",
    "title": "3  Probabilistic Learning with Naive Bayes Classification",
    "section": "3.2 Data Understanding",
    "text": "3.2 Data Understanding\nThe data you’ll be using comes from the SMS Spam Collection (“UCI Machine Learning Repository: SMS Spam Collection Data Set” n.d.). It contains a set of SMS messages that are labeled ‘ham’ or ‘spam’. and is a standard data set for testing spam filtering methods.\n\nurl = \"datasets/smsspam.csv\"\nrawDF = pd.read_csv(url)\nrawDF.head()\n\n   type                                               text\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...\n\n\nThe variable type is of class object which in Python refers to text. As this variable indicates whether the message belongs to the category ham or spam it is better to convert it to a category variable.\n\ncatType = CategoricalDtype(categories=[\"ham\", \"spam\"], ordered=False)\nrawDF.type = rawDF.type.astype(catType)\nrawDF.type\n\n0        ham\n1        ham\n2       spam\n3        ham\n4        ham\n        ... \n5567    spam\n5568     ham\n5569     ham\n5570     ham\n5571     ham\nName: type, Length: 5572, dtype: category\nCategories (2, object): ['ham', 'spam']\n\n\nTo see how the types of sms messages are distributed you can compare the counts for each category.\n\nrawDF.type.value_counts()\n\nham     4825\nspam     747\nName: type, dtype: int64\n\n\nOften you’ll prefer the relative counts.\n\nrawDF.type.value_counts(normalize=True)\n\nham     0.865937\nspam    0.134063\nName: type, dtype: float64\n\n\nYou can also visually inspect the data by creating wordclouds for each sms type.\n\n# Generate a word cloud image]\nhamText = ' '.join([Text for Text in rawDF[rawDF['type']=='ham']['text']])\nspamText = ' '.join([Text for Text in rawDF[rawDF['type']=='spam']['text']])\ncolorListHam=['#e9f6fb','#92d2ed','#2195c5']\ncolorListSpam=['#f9ebeb','#d57676','#b03636']\ncolormapHam=colors.ListedColormap(colorListHam)\ncolormapSpam=colors.ListedColormap(colorListSpam)\nwordcloudHam = WordCloud(background_color='white', colormap=colormapHam).generate(hamText)\nwordcloudSpam = WordCloud(background_color='white', colormap=colormapSpam).generate(spamText)\n\n# Display the generated image:\n# the matplotlib way:\nfig, (wc1, wc2) = plt.subplots(1, 2)\nfig.suptitle('Wordclouds for ham and spam')\nwc1.imshow(wordcloudHam)\nwc2.imshow(wordcloudSpam)\nplt.show()\n\n\n\n\nQuestion:\n\nWhat differences do you notice?"
  },
  {
    "objectID": "nb.html#preparation",
    "href": "nb.html#preparation",
    "title": "3  Probabilistic Learning with Naive Bayes Classification",
    "section": "3.3 Preparation",
    "text": "3.3 Preparation\nAfter you’ve glimpsed over the data and have a certain understanding of its structure and content, you are now ready to prepare the data for further processing. For the naive bayes model you’ll need to have a dataframe with wordcounts. To save on computation time you can set a limit on the number of features (columns) in the wordsDF dataframe.\n\nvectorizer = TfidfVectorizer(max_features=1000)\nvectors = vectorizer.fit_transform(rawDF.text)\nwordsDF = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\nwordsDF.head()\n\n   000   03   04  0800  08000839402  ...  your  yours  yourself   yr  yup\n0  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n1  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n2  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n3  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n4  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n\n[5 rows x 1000 columns]\n\n\nThe counts are normalized in such a way that the words that are most likely to have predictive power get heavier weights. For instance stopword like “a” and “for” most probably will equally likely feature in spam as in ham messages. Therefore these words will be assigned lower normalized counts.\nBefore we start modeling we need to split all datasets into train and test sets. The function train_test_split() can be used to create balanced splits of the data. In this case we’ll create a 75/25% split.\n\nxTrain, xTest, yTrain, yTest = train_test_split(wordsDF, rawDF.type)"
  },
  {
    "objectID": "nb.html#modeling-and-evaluation",
    "href": "nb.html#modeling-and-evaluation",
    "title": "3  Probabilistic Learning with Naive Bayes Classification",
    "section": "3.4 Modeling and Evaluation",
    "text": "3.4 Modeling and Evaluation\nWe have now everything in place to start training our model and evaluate against our test dataset. The MultinomialNB().fit() function is part of the scikit learn package. It takes in the features and labels of our training dataset and returns a trained naive bayes model.\n\nbayes = MultinomialNB()\nbayes.fit(xTrain, yTrain)\n\nMultinomialNB()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.MultinomialNBMultinomialNB()\n\n\nThe model can be applied to the test features using the predict() function which generates a array of predictions. Using a confusion matrix we can analyze the performance of our model.\n\n\n\n\n\nStandard diffusion table. Taken from: https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg\n\n\n\n\n\nyPred = bayes.predict(xTest)\nyTrue = yTest\n\n\naccuracyScore = accuracy_score(yTrue, yPred)\nprint(f'Accuracy: {accuracyScore}')\n\nAccuracy: 0.9777458722182341\n\nmatrix = confusion_matrix(yTrue, yPred)\nlabelNames = pd.Series(['ham', 'spam'])\npd.DataFrame(matrix,\n     columns='Predicted ' + labelNames,\n     index='Is ' + labelNames)\n\n         Predicted ham  Predicted spam\nIs ham            1207               2\nIs spam             29             155\n\n\nQuestions:\n\nWhat do you think is the role of the alpha parameter in the MultinomialNB() function?\nHow would you assess the overall performance of the model?\nWhat would you consider as more costly: high false negatives or high false positives levels? Why?\n\n\n\n\n\n“Spam Statistics: Spam e-Mail Traffic Share 2019.” n.d. Statista. Accessed January 10, 2021. https://www.statista.com/statistics/420391/spam-email-traffic-share/.\n\n\n“UCI Machine Learning Repository: SMS Spam Collection Data Set.” n.d. Accessed January 9, 2021. https://archive.ics.uci.edu/ml/datasets/sms+spam+collection."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "“Spam Statistics: Spam e-Mail Traffic Share 2019.” n.d.\nStatista. Accessed January 10, 2021. https://www.statista.com/statistics/420391/spam-email-traffic-share/.\n\n\n“UCI Machine Learning\nRepository: Breast Cancer\nWisconsin (Diagnostic) Data\nSet.” n.d. Accessed January 7, 2021. https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic).\n\n\n“UCI Machine Learning\nRepository: SMS Spam\nCollection Data Set.” n.d.\nAccessed January 9, 2021. https://archive.ics.uci.edu/ml/datasets/sms+spam+collection.\n\n\n“WHO  Cancer Country\nProfiles 2020.” n.d. WHO. Accessed January 7, 2021. http://www.who.int/cancer/country-profiles/en/."
  }
]
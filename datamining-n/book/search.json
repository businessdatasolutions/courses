[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Mining in Python",
    "section": "",
    "text": "Preface\nWitek ten Hove is a senior instructor and researcher at HAN University of Applied Sciences. His main areas of expertise are Data en Web Technologies.\nThrough his extensive business experience in Finance and International Trade and thorough knowledge of modern data technologies, he is able to make connections between technology and business. As an open source evangelist he firmly believe in the power of knowledge sharing. His mission is to inspire business professionals and help them exploit the full potential of smart technologies.\nHe is the owner of Ten Hove Business Data Solutions, a consultancy and training company helping organizations to achieve maximum business value through data driven solutions."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Data Mining in Python",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore starting this module make sure you have:\n\naccess to the book Provost, F., & Fawcett, T. (2013). Data Science for Business: What you need to know about data mining and data-analytic thinking. O’Reilly Media, Inc.\ninstalled Anaconda\na Github account"
  },
  {
    "objectID": "index.html#purpose-of-this-course",
    "href": "index.html#purpose-of-this-course",
    "title": "Data Mining in Python",
    "section": "Purpose of this course",
    "text": "Purpose of this course\nThe general learning outcome of this course is:\n\nThe student is able to perform a well-defined task independently in a relatively clearly arranged situation, or is able to perform in a complex and unpredictable situation under supervision.\n\nThe course will provide you with a few essential data mining skills. The focus will lie on non-linear modeling techniques - k-Nearest Neighbors (kNN) and Naive Bayes classification.\nAfter a successful completion of the course, a student:\n\nis able to prepare data for a given non-linear model\ntrain en test a non-linear model\nevaluate the quality of a trained model"
  },
  {
    "objectID": "index.html#structure-of-the-course",
    "href": "index.html#structure-of-the-course",
    "title": "Data Mining in Python",
    "section": "Structure of the course",
    "text": "Structure of the course\n\n\n\nCourse overview\n\n\n\n\n\n\n\nWeek nr.\nModule name\nReadings\n\n\n\n\n2\nOnboarding and Introduction to the Course\nProvost / Fawcett Ch.3\n\n\n3-4\nLazy Learning with kNN\nProvost / Fawcett Ch.6 + 7\n\n\n5-6\nProbabilistic Learning with Naive Bayes Classification\nProvost / Fawcett Ch.9\n\n\n7\nProject Application\n\n\n\n\n\n\nThrough the whole of the program you’ll be cooperating within a team where you will combine and compare the results of the different case studies. At the end of the course you will present with your team what you have learned from analyzing and comparing the different case studies."
  },
  {
    "objectID": "setup.html#working-with-quarto",
    "href": "setup.html#working-with-quarto",
    "title": "1  Setting up your data science environment",
    "section": "1.1 Working with Quarto",
    "text": "1.1 Working with Quarto"
  },
  {
    "objectID": "setup.html#working-with-git-and-github",
    "href": "setup.html#working-with-git-and-github",
    "title": "1  Setting up your data science environment",
    "section": "1.2 Working with Git and Github",
    "text": "1.2 Working with Git and Github"
  },
  {
    "objectID": "setup.html#using-python-virtual-environments",
    "href": "setup.html#using-python-virtual-environments",
    "title": "1  Setting up your data science environment",
    "section": "1.3 Using Python virtual environments",
    "text": "1.3 Using Python virtual environments"
  },
  {
    "objectID": "knn.html#business-case-diagnosing-breast-cancer",
    "href": "knn.html#business-case-diagnosing-breast-cancer",
    "title": "2  Lazy learning with k-Nearest Neighbors",
    "section": "2.1 Business Case: Diagnosing Breast Cancer",
    "text": "2.1 Business Case: Diagnosing Breast Cancer\nBreast cancer is the top cancer in women both in the developed and the developing world. In the Netherlands it is the most pervasive form of cancer (“WHO  Cancer Country Profiles 2020” n.d.). In order to improve breast cancer outcome and survival early detection remains the most important instrument for breast cancer control. If machine learning could automate the identification of cancer, it would improve efficiency of the detection process and might also increase its effectiveness by providing greater detection accuracy."
  },
  {
    "objectID": "knn.html#data-understanding",
    "href": "knn.html#data-understanding",
    "title": "2  Lazy learning with k-Nearest Neighbors",
    "section": "2.2 Data Understanding",
    "text": "2.2 Data Understanding\nThe data we will be using comes from the University of Wisconsin and is available online as an open source dataset (“UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set” n.d.). It includes measurements from digitized images from from fine-needle aspirates of breast mass. The values represent cell nuclei features.\nFor convenience the data in csv format is stored on Github. We can access it directly using a function for reading csv from the pandas library\n\nurl = \"https://raw.githubusercontent.com/businessdatasolutions/courses/main/data%20mining/gitbook/datasets/breastcancer.csv\"\nrawDF = pd.read_csv(url)\n\nUsing the info() function we can have some basic information about the dataset.\n\nrawDF.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 32 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 569 non-null    int64  \n 1   diagnosis          569 non-null    object \n 2   radius_mean        569 non-null    float64\n 3   texture_mean       569 non-null    float64\n 4   perimeter_mean     569 non-null    float64\n 5   area_mean          569 non-null    float64\n 6   smoothness_mean    569 non-null    float64\n 7   compactness_mean   569 non-null    float64\n 8   concavity_mean     569 non-null    float64\n 9   points_mean        569 non-null    float64\n 10  symmetry_mean      569 non-null    float64\n 11  dimension_mean     569 non-null    float64\n 12  radius_se          569 non-null    float64\n 13  texture_se         569 non-null    float64\n 14  perimeter_se       569 non-null    float64\n 15  area_se            569 non-null    float64\n 16  smoothness_se      569 non-null    float64\n 17  compactness_se     569 non-null    float64\n 18  concavity_se       569 non-null    float64\n 19  points_se          569 non-null    float64\n 20  symmetry_se        569 non-null    float64\n 21  dimension_se       569 non-null    float64\n 22  radius_worst       569 non-null    float64\n 23  texture_worst      569 non-null    float64\n 24  perimeter_worst    569 non-null    float64\n 25  area_worst         569 non-null    float64\n 26  smoothness_worst   569 non-null    float64\n 27  compactness_worst  569 non-null    float64\n 28  concavity_worst    569 non-null    float64\n 29  points_worst       569 non-null    float64\n 30  symmetry_worst     569 non-null    float64\n 31  dimension_worst    569 non-null    float64\ndtypes: float64(30), int64(1), object(1)\nmemory usage: 142.4+ KB\n\n\nThe dataset has python rawDF.shape()[0] variables (columns)."
  },
  {
    "objectID": "knn.html#preparation",
    "href": "knn.html#preparation",
    "title": "2  Lazy learning with k-Nearest Neighbors",
    "section": "2.3 Preparation",
    "text": "2.3 Preparation\nThe first variable, id, contains unique patient IDs. The IDs do not contain any relevant information for making predictions, so we will delete it from the dataset.\n\ncleanDF = rawDF.drop(['id'], axis=1)\ncleanDF.head()\n\n  diagnosis  radius_mean  ...  symmetry_worst  dimension_worst\n0         B        12.32  ...          0.2827          0.06771\n1         B        10.60  ...          0.2940          0.07587\n2         B        11.04  ...          0.2998          0.07881\n3         B        11.28  ...          0.2102          0.06784\n4         B        15.19  ...          0.2487          0.06766\n\n[5 rows x 31 columns]\n\n\nThe variable named diagnosis contains the outcomes we would like to predict - ‘B’ for ‘Benign’ and ‘M’ for ‘Malignant’. The variable we would like to predict is called the ‘label’. We can look at the counts both outcomes, using the value_counts() function. When we set the normalize setting to True we get the the proportions.\n\ncntDiag = cleanDF['diagnosis'].value_counts()\npropDiag = cleanDF['diagnosis'].value_counts(normalize=True)\ncntDiag\n\nB    357\nM    212\nName: diagnosis, dtype: int64\n\npropDiag\n\nB    0.627417\nM    0.372583\nName: diagnosis, dtype: float64\n\n\nLooking again at the results from the info() function we notice that The variable diagnosis is coded as text (object). Many models require that the label is of type category. The `pandas library contains a function that can transform a object type to category.\n\ncatType = CategoricalDtype(categories=[\"B\", \"M\"], ordered=False)\ncleanDF['diagnosis'] = cleanDF['diagnosis'].astype(catType)\ncleanDF['diagnosis']\n\n0      B\n1      B\n2      B\n3      B\n4      B\n      ..\n564    B\n565    B\n566    M\n567    B\n568    M\nName: diagnosis, Length: 569, dtype: category\nCategories (2, object): ['B', 'M']\n\n\nThe features consist of three different measurements of ten characteristics. We will take three characteristics and have a closer look.\n\ncleanDF[['radius_mean', 'area_mean', 'smoothness_mean']].describe()\n\n       radius_mean    area_mean  smoothness_mean\ncount   569.000000   569.000000       569.000000\nmean     14.127292   654.889104         0.096360\nstd       3.524049   351.914129         0.014064\nmin       6.981000   143.500000         0.052630\n25%      11.700000   420.300000         0.086370\n50%      13.370000   551.100000         0.095870\n75%      15.780000   782.700000         0.105300\nmax      28.110000  2501.000000         0.163400\n\n\nYou’ll notice that the three variables have very different ranges and as a consequence area_mean will have a larger impact on the distance calculation than the smootness_mean. This could potentially cause problems for modeling. To solve this we’ll apply normalization to rescale all features to a standard range of values.\nWe will write our own normalization function.\n\n\ndef normalize(x):\n  return((x - min(x)) / (max(x) - min(x))) # distance of item value - minimum vector value divided by the range of all vector values\n\ntestSet1 = np.arange(1,6)\ntestSet2 = np.arange(1,6) * 10\n\n\n\nprint(f'testSet1: {testSet1}\\n')\n\ntestSet1: [1 2 3 4 5]\n\nprint(f'testSet2: {testSet1}\\n')\n\ntestSet2: [1 2 3 4 5]\n\nprint(f'Normalized testSet1: {normalize(testSet1)}\\n')\n\nNormalized testSet1: [0.   0.25 0.5  0.75 1.  ]\n\nprint(f'Normalized testSet2: {normalize(testSet2)}\\n')\n\nNormalized testSet2: [0.   0.25 0.5  0.75 1.  ]\n\n\nand apply it to all the numerical variables in the dataframe.\n\n\nexcluded = ['diagnosis'] # list of columns to exclude\nX = cleanDF.loc[:, ~cleanDF.columns.isin(excluded)]\nX = X.apply(normalize, axis=0)\nX[['radius_mean', 'area_mean', 'smoothness_mean']].describe()\n\n       radius_mean   area_mean  smoothness_mean\ncount   569.000000  569.000000       569.000000\nmean      0.338222    0.216920         0.394785\nstd       0.166787    0.149274         0.126967\nmin       0.000000    0.000000         0.000000\n25%       0.223342    0.117413         0.304595\n50%       0.302381    0.172895         0.390358\n75%       0.416442    0.271135         0.475490\nmax       1.000000    1.000000         1.000000\n\n\nWhen we take the variables we selected earlier and look at the summary parameters again, we’ll see that the normalization was successful.\nWe can now split our data into training and test sets.\n\ny = cleanDF['diagnosis']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n\nHere, X_train and y_train are the features and labels of the training data, respectively, and X_test and y_test are the features and labels of the test data. Now we can train and evaluate our kNN model."
  },
  {
    "objectID": "knn.html#modeling-and-evaluation",
    "href": "knn.html#modeling-and-evaluation",
    "title": "2  Lazy learning with k-Nearest Neighbors",
    "section": "2.4 Modeling and Evaluation",
    "text": "2.4 Modeling and Evaluation\nKNN is a instance-based learning algorithm. It stores all of the training data and makes predictions based on the similarity between the input instance and the stored instances. The prediction is based on the majority class among the K nearest neighbors of the input instance.\nThe distance between instances is typically measured using the Euclidean distance. However, other distance measures such as the Manhattan distance or the Minkowski distance can also be used.\nThe pseudocode for the KNN algorithm is as follows:\n\n\nfor each instance in the test set:\n    for each instance in the training set:\n        calculate the distance between the two instances\n    sort the distances in ascending order\n    find the K nearest neighbors\n    predict the class based on the majority class among the K nearest neighbors\n\n\nTo train the knn model we only need one single function from the sklearn library. The fit() function trains the model on the training data. The trained model is applied to the set with test features and the predict() function gives back a set of predicted values for y.\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n# make predictions on the test set\n\nKNeighborsClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifierKNeighborsClassifier()\n\ny_pred = knn.predict(X_test)\n\nNow that we have a set of predicted labels we can compare these with the actual labels. A diffusion table shows how well the model performed.\n\n\n\n\n\nStandard diffusion table. Taken from: https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg\n\n\n\n\nHere is our own table:\n\ncm = confusion_matrix(y_test, y_pred, labels=knn.classes_)\ncm\n\narray([[106,   1],\n       [  2,  62]])\n\n\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_)\ndisp.plot()\n\n<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x1a7f9c8b0>\n\nplt.show()\n\n\n\n\nQuestions:\n\nHow would you assess the overall performance of the model?\nWhat would you consider as more costly: high false negatives or high false positives levels? Why?\nTry to improve the model by changing some parameters of the KNeighborsClassifier() function\n\n\n\n\n\n“UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set.” n.d. Accessed January 7, 2021. https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic).\n\n\n“WHO  Cancer Country Profiles 2020.” n.d. WHO. Accessed January 7, 2021. http://www.who.int/cancer/country-profiles/en/."
  },
  {
    "objectID": "nb.html#business-case-filtering-spam",
    "href": "nb.html#business-case-filtering-spam",
    "title": "3  Probabilistic Learning with Naive Bayes Classification",
    "section": "3.1 Business Case: Filtering Spam",
    "text": "3.1 Business Case: Filtering Spam\nIn 2020 spam accounted for more than 50% of total e-mail traffic (“Spam Statistics: Spam e-Mail Traffic Share 2019” n.d.). This illustrates the value of a good spam filter. Naive Bayes spam filtering is a standard technique for handling spam. It is one of the oldest ways of doing spam filtering, with roots in the 1990s."
  },
  {
    "objectID": "nb.html#data-understanding",
    "href": "nb.html#data-understanding",
    "title": "3  Probabilistic Learning with Naive Bayes Classification",
    "section": "3.2 Data Understanding",
    "text": "3.2 Data Understanding\nThe data you’ll be using comes from the SMS Spam Collection (“UCI Machine Learning Repository: SMS Spam Collection Data Set” n.d.). It contains a set of SMS messages that are labeled ‘ham’ or ‘spam’. and is a standard data set for testing spam filtering methods.\n\nurl = \"datasets/smsspam.csv\"\nrawDF = pd.read_csv(url)\nrawDF.head()\n\n   type                                               text\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...\n\n\nThe variable type is of class object which in Python refers to text. As this variable indicates whether the message belongs to the category ham or spam it is better to convert it to a category variable.\n\ncatType = CategoricalDtype(categories=[\"ham\", \"spam\"], ordered=False)\nrawDF.type = rawDF.type.astype(catType)\nrawDF.type\n\n0        ham\n1        ham\n2       spam\n3        ham\n4        ham\n        ... \n5567    spam\n5568     ham\n5569     ham\n5570     ham\n5571     ham\nName: type, Length: 5572, dtype: category\nCategories (2, object): ['ham', 'spam']\n\n\nTo see how the types of sms messages are distributed you can compare the counts for each category.\n\nrawDF.type.value_counts()\n\nham     4825\nspam     747\nName: type, dtype: int64\n\n\nOften you’ll prefer the relative counts.\n\nrawDF.type.value_counts(normalize=True)\n\nham     0.865937\nspam    0.134063\nName: type, dtype: float64\n\n\nYou can also visually inspect the data by creating wordclouds for each sms type.\n\n# Generate a word cloud image]\nhamText = ' '.join([Text for Text in rawDF[rawDF['type']=='ham']['text']])\nspamText = ' '.join([Text for Text in rawDF[rawDF['type']=='spam']['text']])\ncolorListHam=['#e9f6fb','#92d2ed','#2195c5']\ncolorListSpam=['#f9ebeb','#d57676','#b03636']\ncolormapHam=colors.ListedColormap(colorListHam)\ncolormapSpam=colors.ListedColormap(colorListSpam)\nwordcloudHam = WordCloud(background_color='white', colormap=colormapHam).generate(hamText)\nwordcloudSpam = WordCloud(background_color='white', colormap=colormapSpam).generate(spamText)\n\n# Display the generated image:\n# the matplotlib way:\nfig, (wc1, wc2) = plt.subplots(1, 2)\nfig.suptitle('Wordclouds for ham and spam')\nwc1.imshow(wordcloudHam)\nwc2.imshow(wordcloudSpam)\nplt.show()\n\n\n\n\nQuestion:\n\nWhat differences do you notice?"
  },
  {
    "objectID": "nb.html#preparation",
    "href": "nb.html#preparation",
    "title": "3  Probabilistic Learning with Naive Bayes Classification",
    "section": "3.3 Preparation",
    "text": "3.3 Preparation\nAfter you’ve glimpsed over the data and have a certain understanding of its structure and content, you are now ready to prepare the data for further processing. For the naive bayes model you’ll need to have a dataframe with wordcounts. To save on computation time you can set a limit on the number of features (columns) in the wordsDF dataframe.\n\nvectorizer = TfidfVectorizer(max_features=1000)\nvectors = vectorizer.fit_transform(rawDF.text)\nwordsDF = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\nwordsDF.head()\n\n   000   03   04  0800  08000839402  ...  your  yours  yourself   yr  yup\n0  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n1  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n2  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n3  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n4  0.0  0.0  0.0   0.0          0.0  ...   0.0    0.0       0.0  0.0  0.0\n\n[5 rows x 1000 columns]\n\n\nThe counts are normalized in such a way that the words that are most likely to have predictive power get heavier weights. For instance stopword like “a” and “for” most probably will equally likely feature in spam as in ham messages. Therefore these words will be assigned lower normalized counts.\nBefore we start modeling we need to split all datasets into train and test sets. The function train_test_split() can be used to create balanced splits of the data. In this case we’ll create a 75/25% split.\n\nxTrain, xTest, yTrain, yTest = train_test_split(wordsDF, rawDF.type)"
  },
  {
    "objectID": "nb.html#modeling-and-evaluation",
    "href": "nb.html#modeling-and-evaluation",
    "title": "3  Probabilistic Learning with Naive Bayes Classification",
    "section": "3.4 Modeling and Evaluation",
    "text": "3.4 Modeling and Evaluation\nWe have now everything in place to start training our model and evaluate against our test dataset. The MultinomialNB().fit() function is part of the scikit learn package. It takes in the features and labels of our training dataset and returns a trained naive bayes model.\n\nbayes = MultinomialNB()\nbayes.fit(xTrain, yTrain)\n\nMultinomialNB()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.MultinomialNBMultinomialNB()\n\n\nThe model can be applied to the test features using the predict() function which generates a array of predictions. Using a confusion matrix we can analyze the performance of our model.\n\n\n\n\n\nStandard diffusion table. Taken from: https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg\n\n\n\n\n\nyPred = bayes.predict(xTest)\nyTrue = yTest\n\n\naccuracyScore = accuracy_score(yTrue, yPred)\nprint(f'Accuracy: {accuracyScore}')\n\nAccuracy: 0.9741564967695621\n\nmatrix = confusion_matrix(yTrue, yPred)\nlabelNames = pd.Series(['ham', 'spam'])\npd.DataFrame(matrix,\n     columns='Predicted ' + labelNames,\n     index='Is ' + labelNames)\n\n         Predicted ham  Predicted spam\nIs ham            1196               5\nIs spam             31             161\n\n\nQuestions:\n\nWhat do you think is the role of the alpha parameter in the MultinomialNB() function?\nHow would you assess the overall performance of the model?\nWhat would you consider as more costly: high false negatives or high false positives levels? Why?\n\n\n\n\n\n“Spam Statistics: Spam e-Mail Traffic Share 2019.” n.d. Statista. Accessed January 10, 2021. https://www.statista.com/statistics/420391/spam-email-traffic-share/.\n\n\n“UCI Machine Learning Repository: SMS Spam Collection Data Set.” n.d. Accessed January 9, 2021. https://archive.ics.uci.edu/ml/datasets/sms+spam+collection."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "“Spam Statistics: Spam e-Mail Traffic Share 2019.” n.d.\nStatista. Accessed January 10, 2021. https://www.statista.com/statistics/420391/spam-email-traffic-share/.\n\n\n“UCI Machine Learning\nRepository: Breast Cancer\nWisconsin (Diagnostic) Data\nSet.” n.d. Accessed January 7, 2021. https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic).\n\n\n“UCI Machine Learning\nRepository: SMS Spam\nCollection Data Set.” n.d.\nAccessed January 9, 2021. https://archive.ics.uci.edu/ml/datasets/sms+spam+collection.\n\n\n“WHO  Cancer Country\nProfiles 2020.” n.d. WHO. Accessed January 7, 2021. http://www.who.int/cancer/country-profiles/en/."
  }
]
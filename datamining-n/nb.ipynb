{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Probabilistic Learning with Naive Bayes Classification {#naivebayes}\n",
        "\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/O2L2Uv9pdDA\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
        "\n",
        "</iframe>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import CategoricalDtype\n",
        "from IPython.display import display, Markdown\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business Case: Filtering Spam\n",
        "\n",
        "In 2020 spam accounted for more than 50% of total e-mail traffic [@noauthor_spam_nodate]. This illustrates the value of a good spam filter. Naive Bayes spam filtering is a standard technique for handling spam. It is one of the oldest ways of doing spam filtering, with roots in the 1990s.\n",
        "\n",
        "## Data Understanding\n",
        "\n",
        "The data you'll be using comes from the SMS Spam Collection [@noauthor_uci_spam_nodate]. It contains a set of SMS messages that are labeled 'ham' or 'spam'. and is a standard data set for testing spam filtering methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "url = \"datasets/smsspam.csv\"\n",
        "rawDF = pd.read_csv(url)\n",
        "rawDF.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The variable `type` is of class `object` which in Python refers to text. As this variable indicates whether the message belongs to the category ham or spam it is better to convert it to a `category` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "catType = CategoricalDtype(categories=[\"ham\", \"spam\"], ordered=False)\n",
        "rawDF.type = rawDF.type.astype(catType)\n",
        "rawDF.type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see how the types of sms messages are distributed you can compare the counts for each category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rawDF.type.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Often you'll prefer the relative counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rawDF.type.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also visually inspect the data by creating wordclouds for each sms type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate a word cloud image]\n",
        "hamText = ' '.join([Text for Text in rawDF[rawDF['type']=='ham']['text']])\n",
        "spamText = ' '.join([Text for Text in rawDF[rawDF['type']=='spam']['text']])\n",
        "colorListHam=['#e9f6fb','#92d2ed','#2195c5']\n",
        "colorListSpam=['#f9ebeb','#d57676','#b03636']\n",
        "colormapHam=colors.ListedColormap(colorListHam)\n",
        "colormapSpam=colors.ListedColormap(colorListSpam)\n",
        "wordcloudHam = WordCloud(background_color='white', colormap=colormapHam).generate(hamText)\n",
        "wordcloudSpam = WordCloud(background_color='white', colormap=colormapSpam).generate(spamText)\n",
        "\n",
        "# Display the generated image:\n",
        "# the matplotlib way:\n",
        "fig, (wc1, wc2) = plt.subplots(1, 2)\n",
        "fig.suptitle('Wordclouds for ham and spam')\n",
        "wc1.imshow(wordcloudHam)\n",
        "wc2.imshow(wordcloudSpam)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:**\n",
        "\n",
        "-   *What differences do you notice?*\n",
        "\n",
        "## Preparation\n",
        "\n",
        "After you've glimpsed over the data and have a certain understanding of its structure and content, you are now ready to prepare the data for further processing. For the naive bayes model you'll need to have a dataframe with wordcounts. To save on computation time you can set a limit on the number of features (columns) in the wordsDF dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "vectors = vectorizer.fit_transform(rawDF.text)\n",
        "wordsDF = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "wordsDF.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The counts are normalized in such a way that the words that are most likely to have predictive power get heavier weights. For instance stopword like *\"a\"* and *\"for\"* most probably will equally likely feature in spam as in ham messages. Therefore these words will be assigned lower normalized counts.\n",
        "\n",
        "Before we start modeling we need to split all datasets into *train* and *test* sets. The function *train_test_split`()`* can be used to create balanced splits of the data. In this case we'll create a 75/25% split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "xTrain, xTest, yTrain, yTest = train_test_split(wordsDF, rawDF.type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling and Evaluation\n",
        "\n",
        "We have now everything in place to start training our model and evaluate against our test dataset. The `MultinomialNB().fit()` function is part of the `scikit learn` package. It takes in the features and labels of our training dataset and returns a trained naive bayes model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bayes = MultinomialNB()\n",
        "bayes.fit(xTrain, yTrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model can be applied to the test features using the `predict()` function which generates a array of predictions. Using a confusion matrix we can analyze the performance of our model.\n",
        "\n",
        "```{r difftable1-fig, echo=FALSE, fig.align='center', fig.asp=.75, fig.cap='Standard diffusion table. Taken from: https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg', message=TRUE, warning=TRUE, out.width='80%'}\n",
        "knitr::include_graphics(rep('images/diffusion.png'))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "yPred = bayes.predict(xTest)\n",
        "yTrue = yTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "accuracyScore = accuracy_score(yTrue, yPred)\n",
        "print(f'Accuracy: {accuracyScore}')\n",
        "matrix = confusion_matrix(yTrue, yPred)\n",
        "labelNames = pd.Series(['ham', 'spam'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + labelNames,\n",
        "     index='Is ' + labelNames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Questions:**\n",
        "\n",
        "1.  *What do you think is the role of the `alpha` parameter in the `MultinomialNB()` function?*\n",
        "2.  *How would you assess the overall performance of the model?*\n",
        "3.  *What would you consider as more costly: high false negatives or high false positives levels? Why?*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "osmnx",
      "language": "python",
      "display_name": "osmnx"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
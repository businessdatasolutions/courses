<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Module 2 Lazy learning with k-Nearest Neighbors | Data Mining</title>
  <meta name="description" content="This is a compagnon to the course Data Mining." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Module 2 Lazy learning with k-Nearest Neighbors | Data Mining" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a compagnon to the course Data Mining." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Module 2 Lazy learning with k-Nearest Neighbors | Data Mining" />
  
  <meta name="twitter:description" content="This is a compagnon to the course Data Mining." />
  

<meta name="author" content="Witek ten hove" />


<meta name="date" content="2021-01-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="dm.html"/>
<link rel="next" href="naivebayes.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science for Business</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#purpose-of-this-course"><i class="fa fa-check"></i>Purpose of this course</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-course"><i class="fa fa-check"></i>Structure of the course</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the author</a></li>
<li class="chapter" data-level="1" data-path="dm.html"><a href="dm.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="dm.html"><a href="dm.html#working-with-rmarkdown"><i class="fa fa-check"></i><b>1.1</b> Working with RMarkdown</a></li>
<li class="chapter" data-level="1.2" data-path="dm.html"><a href="dm.html#working-with-git-and-github"><i class="fa fa-check"></i><b>1.2</b> Working with Git and Github</a></li>
<li class="chapter" data-level="1.3" data-path="dm.html"><a href="dm.html#customizing-rmarkdown-with-html-and-css"><i class="fa fa-check"></i><b>1.3</b> Customizing RMarkdown with HTML and CSS</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="knn.html"><a href="knn.html"><i class="fa fa-check"></i><b>2</b> Lazy learning with k-Nearest Neighbors</a><ul>
<li class="chapter" data-level="2.1" data-path="knn.html"><a href="knn.html#business-case-diagnosing-breast-cancer"><i class="fa fa-check"></i><b>2.1</b> Business Case: Diagnosing Breast Cancer</a></li>
<li class="chapter" data-level="2.2" data-path="knn.html"><a href="knn.html#data-understanding"><i class="fa fa-check"></i><b>2.2</b> Data Understanding</a></li>
<li class="chapter" data-level="2.3" data-path="knn.html"><a href="knn.html#preparation"><i class="fa fa-check"></i><b>2.3</b> Preparation</a></li>
<li class="chapter" data-level="2.4" data-path="knn.html"><a href="knn.html#modeling"><i class="fa fa-check"></i><b>2.4</b> Modeling</a></li>
<li class="chapter" data-level="2.5" data-path="knn.html"><a href="knn.html#evaluation"><i class="fa fa-check"></i><b>2.5</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="naivebayes.html"><a href="naivebayes.html"><i class="fa fa-check"></i><b>3</b> Probabilistic Learning with Naive Bayes Classification</a><ul>
<li class="chapter" data-level="3.1" data-path="naivebayes.html"><a href="naivebayes.html#business-case-filtering-spam"><i class="fa fa-check"></i><b>3.1</b> Business Case: Filtering Spam</a></li>
<li class="chapter" data-level="3.2" data-path="naivebayes.html"><a href="naivebayes.html#data-understanding-1"><i class="fa fa-check"></i><b>3.2</b> Data Understanding</a></li>
<li class="chapter" data-level="3.3" data-path="naivebayes.html"><a href="naivebayes.html#preparation-1"><i class="fa fa-check"></i><b>3.3</b> Preparation</a></li>
<li class="chapter" data-level="3.4" data-path="naivebayes.html"><a href="naivebayes.html#modeling-1"><i class="fa fa-check"></i><b>3.4</b> Modeling</a></li>
<li class="chapter" data-level="3.5" data-path="naivebayes.html"><a href="naivebayes.html#evaluation-1"><i class="fa fa-check"></i><b>3.5</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Mining</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="knn" class="section level1">
<h1><span class="header-section-number">Module 2</span> Lazy learning with k-Nearest Neighbors</h1>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MDniRwXizWo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<div id="business-case-diagnosing-breast-cancer" class="section level2">
<h2><span class="header-section-number">2.1</span> Business Case: Diagnosing Breast Cancer</h2>
<p>Breast cancer is the top cancer in women both in the developed and the developing world. In the Netherlands it is the most pervasive form of cancer <span class="citation">(“WHO Cancer Country Profiles 2020” <a href="#ref-noauthor_who_nodate" role="doc-biblioref">n.d.</a>)</span>. In order to improve breast cancer outcome and survival early detection remains the most important instrument for breast cancer control. If machine learning could automate the identification of cancer, it would improve efficiency of the detection process and might also increase its effectiveness by providing greater detection accuracy.</p>
</div>
<div id="data-understanding" class="section level2">
<h2><span class="header-section-number">2.2</span> Data Understanding</h2>
<p>The data we will be using comes from the University of Wisconsin and is available online as an open source dataset <span class="citation">(“UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set” <a href="#ref-noauthor_uci_cancer_nodate" role="doc-biblioref">n.d.</a>)</span>. It includes measurements from digitized images from from fine-needle aspirates of breast mass. The values represent cell nuclei features.</p>
<p>The data is saved online as a Google Spreadsheet. We can access it directly using a function dedicated to reading Google Spreadsheets from the <code>googlesheets4</code> package.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="knn.html#cb1-1"></a>url &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/businessdatasolutions/courses/main/data%20mining/gitbook/datasets/breastcancer.csv&quot;</span></span>
<span id="cb1-2"><a href="knn.html#cb1-2"></a>rawDF &lt;-<span class="st"> </span><span class="kw">read_csv</span>(url)</span></code></pre></div>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   .default = col_double(),
##   diagnosis = col_character()
## )
## ℹ Use `spec()` for the full column specifications.</code></pre>
<p>Using the <code>str()</code> function we can have some basic information about the dataset.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="knn.html#cb3-1"></a><span class="kw">str</span>(rawDF)</span></code></pre></div>
<pre><code>## tibble [569 × 32] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ id               : num [1:569] 87139402 8910251 905520 868871 9012568 ...
##  $ diagnosis        : chr [1:569] &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; ...
##  $ radius_mean      : num [1:569] 12.3 10.6 11 11.3 15.2 ...
##  $ texture_mean     : num [1:569] 12.4 18.9 16.8 13.4 13.2 ...
##  $ perimeter_mean   : num [1:569] 78.8 69.3 70.9 73 97.7 ...
##  $ area_mean        : num [1:569] 464 346 373 385 712 ...
##  $ smoothness_mean  : num [1:569] 0.1028 0.0969 0.1077 0.1164 0.0796 ...
##  $ compactness_mean : num [1:569] 0.0698 0.1147 0.078 0.1136 0.0693 ...
##  $ concavity_mean   : num [1:569] 0.0399 0.0639 0.0305 0.0464 0.0339 ...
##  $ points_mean      : num [1:569] 0.037 0.0264 0.0248 0.048 0.0266 ...
##  $ symmetry_mean    : num [1:569] 0.196 0.192 0.171 0.177 0.172 ...
##  $ dimension_mean   : num [1:569] 0.0595 0.0649 0.0634 0.0607 0.0554 ...
##  $ radius_se        : num [1:569] 0.236 0.451 0.197 0.338 0.178 ...
##  $ texture_se       : num [1:569] 0.666 1.197 1.387 1.343 0.412 ...
##  $ perimeter_se     : num [1:569] 1.67 3.43 1.34 1.85 1.34 ...
##  $ area_se          : num [1:569] 17.4 27.1 13.5 26.3 17.7 ...
##  $ smoothness_se    : num [1:569] 0.00805 0.00747 0.00516 0.01127 0.00501 ...
##  $ compactness_se   : num [1:569] 0.0118 0.03581 0.00936 0.03498 0.01485 ...
##  $ concavity_se     : num [1:569] 0.0168 0.0335 0.0106 0.0219 0.0155 ...
##  $ points_se        : num [1:569] 0.01241 0.01365 0.00748 0.01965 0.00915 ...
##  $ symmetry_se      : num [1:569] 0.0192 0.035 0.0172 0.0158 0.0165 ...
##  $ dimension_se     : num [1:569] 0.00225 0.00332 0.0022 0.00344 0.00177 ...
##  $ radius_worst     : num [1:569] 13.5 11.9 12.4 11.9 16.2 ...
##  $ texture_worst    : num [1:569] 15.6 22.9 26.4 15.8 15.7 ...
##  $ perimeter_worst  : num [1:569] 87 78.3 79.9 76.5 104.5 ...
##  $ area_worst       : num [1:569] 549 425 471 434 819 ...
##  $ smoothness_worst : num [1:569] 0.139 0.121 0.137 0.137 0.113 ...
##  $ compactness_worst: num [1:569] 0.127 0.252 0.148 0.182 0.174 ...
##  $ concavity_worst  : num [1:569] 0.1242 0.1916 0.1067 0.0867 0.1362 ...
##  $ points_worst     : num [1:569] 0.0939 0.0793 0.0743 0.0861 0.0818 ...
##  $ symmetry_worst   : num [1:569] 0.283 0.294 0.3 0.21 0.249 ...
##  $ dimension_worst  : num [1:569] 0.0677 0.0759 0.0788 0.0678 0.0677 ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   id = col_double(),
##   ..   diagnosis = col_character(),
##   ..   radius_mean = col_double(),
##   ..   texture_mean = col_double(),
##   ..   perimeter_mean = col_double(),
##   ..   area_mean = col_double(),
##   ..   smoothness_mean = col_double(),
##   ..   compactness_mean = col_double(),
##   ..   concavity_mean = col_double(),
##   ..   points_mean = col_double(),
##   ..   symmetry_mean = col_double(),
##   ..   dimension_mean = col_double(),
##   ..   radius_se = col_double(),
##   ..   texture_se = col_double(),
##   ..   perimeter_se = col_double(),
##   ..   area_se = col_double(),
##   ..   smoothness_se = col_double(),
##   ..   compactness_se = col_double(),
##   ..   concavity_se = col_double(),
##   ..   points_se = col_double(),
##   ..   symmetry_se = col_double(),
##   ..   dimension_se = col_double(),
##   ..   radius_worst = col_double(),
##   ..   texture_worst = col_double(),
##   ..   perimeter_worst = col_double(),
##   ..   area_worst = col_double(),
##   ..   smoothness_worst = col_double(),
##   ..   compactness_worst = col_double(),
##   ..   concavity_worst = col_double(),
##   ..   points_worst = col_double(),
##   ..   symmetry_worst = col_double(),
##   ..   dimension_worst = col_double()
##   .. )</code></pre>
<p>The dataset has 32 variables (columns) and 569 observations (rows).</p>
</div>
<div id="preparation" class="section level2">
<h2><span class="header-section-number">2.3</span> Preparation</h2>
<p>The first variable, <code>id</code>, contains unique patient IDs. The IDs do not contain any relevant information for making predictions, so we will delete it from the dataset.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="knn.html#cb5-1"></a>cleanDF &lt;-<span class="st"> </span>rawDF[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-2"><a href="knn.html#cb5-2"></a><span class="kw">head</span>(cleanDF)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 31
##   diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean
##   &lt;chr&gt;           &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;           &lt;dbl&gt;
## 1 B                12.3         12.4           78.8      464.          0.103 
## 2 B                10.6         19.0           69.3      346.          0.0969
## 3 B                11.0         16.8           70.9      373.          0.108 
## 4 B                11.3         13.4           73        385.          0.116 
## 5 B                15.2         13.2           97.6      712.          0.0796
## 6 B                11.6         19.0           74.2      410.          0.0855
## # … with 25 more variables: compactness_mean &lt;dbl&gt;, concavity_mean &lt;dbl&gt;,
## #   points_mean &lt;dbl&gt;, symmetry_mean &lt;dbl&gt;, dimension_mean &lt;dbl&gt;,
## #   radius_se &lt;dbl&gt;, texture_se &lt;dbl&gt;, perimeter_se &lt;dbl&gt;, area_se &lt;dbl&gt;,
## #   smoothness_se &lt;dbl&gt;, compactness_se &lt;dbl&gt;, concavity_se &lt;dbl&gt;,
## #   points_se &lt;dbl&gt;, symmetry_se &lt;dbl&gt;, dimension_se &lt;dbl&gt;, radius_worst &lt;dbl&gt;,
## #   texture_worst &lt;dbl&gt;, perimeter_worst &lt;dbl&gt;, area_worst &lt;dbl&gt;,
## #   smoothness_worst &lt;dbl&gt;, compactness_worst &lt;dbl&gt;, concavity_worst &lt;dbl&gt;,
## #   points_worst &lt;dbl&gt;, symmetry_worst &lt;dbl&gt;, dimension_worst &lt;dbl&gt;</code></pre>
<p>The variable named <code>diagnosis</code> contains the outcomes we would like to predict - ‘B’ for ‘Benign’ and ‘M’ for ‘Malignant’. The variable we would like to predict is called the ‘label’. We can look at the counts and proportions for both outcomes, using the <code>tables()</code> and <code>prop.tables()</code>functions.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="knn.html#cb7-1"></a>cntDiag &lt;-<span class="st"> </span><span class="kw">table</span>(cleanDF<span class="op">$</span>diagnosis)</span>
<span id="cb7-2"><a href="knn.html#cb7-2"></a>propDiag &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">prop.table</span>(cntDiag) <span class="op">*</span><span class="st"> </span><span class="dv">100</span> , <span class="dt">digits =</span> <span class="dv">1</span>)</span>
<span id="cb7-3"><a href="knn.html#cb7-3"></a></span>
<span id="cb7-4"><a href="knn.html#cb7-4"></a>cntDiag</span></code></pre></div>
<pre><code>## 
##   B   M 
## 357 212</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="knn.html#cb9-1"></a>propDiag</span></code></pre></div>
<pre><code>## 
##    B    M 
## 62.7 37.3</code></pre>
<p>The variable is now coded as a type <code>character</code>. Many models require that the label is of type <code>factor</code>. This is easily solved using the <code>factor()</code> function.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="knn.html#cb11-1"></a>cleanDF<span class="op">$</span>diagnosis &lt;-<span class="st"> </span><span class="kw">factor</span>(cleanDF<span class="op">$</span>diagnosis, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;B&quot;</span>, <span class="st">&quot;M&quot;</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Benign&quot;</span>, <span class="st">&quot;Malignant&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">relevel</span>(<span class="st">&quot;Malignant&quot;</span>)</span>
<span id="cb11-2"><a href="knn.html#cb11-2"></a><span class="kw">head</span>(cleanDF, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 31
##    diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean
##    &lt;fct&gt;           &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;           &lt;dbl&gt;
##  1 Benign           12.3         12.4           78.8      464.          0.103 
##  2 Benign           10.6         19.0           69.3      346.          0.0969
##  3 Benign           11.0         16.8           70.9      373.          0.108 
##  4 Benign           11.3         13.4           73        385.          0.116 
##  5 Benign           15.2         13.2           97.6      712.          0.0796
##  6 Benign           11.6         19.0           74.2      410.          0.0855
##  7 Benign           11.5         23.9           74.5      404.          0.0926
##  8 Malignant        13.8         23.8           91.6      598.          0.132 
##  9 Benign           10.5         19.3           67.4      336.          0.0999
## 10 Benign           11.1         15.0           71.5      374.          0.103 
## # … with 25 more variables: compactness_mean &lt;dbl&gt;, concavity_mean &lt;dbl&gt;,
## #   points_mean &lt;dbl&gt;, symmetry_mean &lt;dbl&gt;, dimension_mean &lt;dbl&gt;,
## #   radius_se &lt;dbl&gt;, texture_se &lt;dbl&gt;, perimeter_se &lt;dbl&gt;, area_se &lt;dbl&gt;,
## #   smoothness_se &lt;dbl&gt;, compactness_se &lt;dbl&gt;, concavity_se &lt;dbl&gt;,
## #   points_se &lt;dbl&gt;, symmetry_se &lt;dbl&gt;, dimension_se &lt;dbl&gt;, radius_worst &lt;dbl&gt;,
## #   texture_worst &lt;dbl&gt;, perimeter_worst &lt;dbl&gt;, area_worst &lt;dbl&gt;,
## #   smoothness_worst &lt;dbl&gt;, compactness_worst &lt;dbl&gt;, concavity_worst &lt;dbl&gt;,
## #   points_worst &lt;dbl&gt;, symmetry_worst &lt;dbl&gt;, dimension_worst &lt;dbl&gt;</code></pre>
<p>The features consist of three different measurements of ten characteristics. We will take three characteristics and have a closer look.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="knn.html#cb13-1"></a><span class="kw">summary</span>(cleanDF[<span class="kw">c</span>(<span class="st">&quot;radius_mean&quot;</span>, <span class="st">&quot;area_mean&quot;</span>, <span class="st">&quot;smoothness_mean&quot;</span>)])</span></code></pre></div>
<pre><code>##   radius_mean       area_mean      smoothness_mean  
##  Min.   : 6.981   Min.   : 143.5   Min.   :0.05263  
##  1st Qu.:11.700   1st Qu.: 420.3   1st Qu.:0.08637  
##  Median :13.370   Median : 551.1   Median :0.09587  
##  Mean   :14.127   Mean   : 654.9   Mean   :0.09636  
##  3rd Qu.:15.780   3rd Qu.: 782.7   3rd Qu.:0.10530  
##  Max.   :28.110   Max.   :2501.0   Max.   :0.16340</code></pre>
<p>You’ll notice that the three variables have very different ranges and as a consequence <code>area_mean</code> will have a larger impact on the distance calculation than the <code>smootness_mean</code>. This could potentially cause problems for modeling. To solve this we’ll apply normalization to rescale all features to a standard range of values.</p>
<p>We will write our own normalization function.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="knn.html#cb15-1"></a>normalize &lt;-<span class="st"> </span><span class="cf">function</span>(x) { <span class="co"># Function takes in a vector</span></span>
<span id="cb15-2"><a href="knn.html#cb15-2"></a>  <span class="kw">return</span> ((x <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(x)) <span class="op">/</span><span class="st"> </span>(<span class="kw">max</span>(x) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(x))) <span class="co"># distance of item value - minimum vector value divided by the range of all vector values</span></span>
<span id="cb15-3"><a href="knn.html#cb15-3"></a>}</span>
<span id="cb15-4"><a href="knn.html#cb15-4"></a></span>
<span id="cb15-5"><a href="knn.html#cb15-5"></a>testSet1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)</span>
<span id="cb15-6"><a href="knn.html#cb15-6"></a>testSet2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>) <span class="op">*</span><span class="st"> </span><span class="dv">10</span></span>
<span id="cb15-7"><a href="knn.html#cb15-7"></a></span>
<span id="cb15-8"><a href="knn.html#cb15-8"></a><span class="kw">cat</span>(<span class="st">&quot;testSet1:&quot;</span>, testSet1, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## testSet1: 1 2 3 4 5</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="knn.html#cb17-1"></a><span class="kw">cat</span>(<span class="st">&quot;testSet2:&quot;</span>, testSet2, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## testSet2: 10 20 30 40 50</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="knn.html#cb19-1"></a><span class="kw">cat</span>(<span class="st">&quot;Normalized testSet1:&quot;</span>, <span class="kw">normalize</span>(testSet1), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Normalized testSet1: 0 0.25 0.5 0.75 1</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="knn.html#cb21-1"></a><span class="kw">cat</span>(<span class="st">&quot;Normalized testSet2:&quot;</span>, <span class="kw">normalize</span>(testSet2))</span></code></pre></div>
<pre><code>## Normalized testSet2: 0 0.25 0.5 0.75 1</code></pre>
<p>We’ll apply the <code>normalize()</code> function to each feature in the dataset (so, not on the label) using the <code>sapply()</code> function.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="knn.html#cb23-1"></a>nCols &lt;-<span class="st"> </span><span class="kw">dim</span>(cleanDF)[<span class="dv">2</span>]</span>
<span id="cb23-2"><a href="knn.html#cb23-2"></a>cleanDF_n &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">2</span><span class="op">:</span>nCols,</span>
<span id="cb23-3"><a href="knn.html#cb23-3"></a>                    <span class="cf">function</span>(x) {</span>
<span id="cb23-4"><a href="knn.html#cb23-4"></a>  <span class="kw">normalize</span>(cleanDF[,x])</span>
<span id="cb23-5"><a href="knn.html#cb23-5"></a>}) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb23-6"><a href="knn.html#cb23-6"></a></span>
<span id="cb23-7"><a href="knn.html#cb23-7"></a><span class="kw">summary</span>(cleanDF_n[<span class="kw">c</span>(<span class="st">&quot;radius_mean&quot;</span>, <span class="st">&quot;area_mean&quot;</span>, <span class="st">&quot;smoothness_mean&quot;</span>)])</span></code></pre></div>
<pre><code>##   radius_mean       area_mean      smoothness_mean 
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.2233   1st Qu.:0.1174   1st Qu.:0.3046  
##  Median :0.3024   Median :0.1729   Median :0.3904  
##  Mean   :0.3382   Mean   :0.2169   Mean   :0.3948  
##  3rd Qu.:0.4164   3rd Qu.:0.2711   3rd Qu.:0.4755  
##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000</code></pre>
<p>When we take the variables we selected earlier and look at the summary parameters again, we’ll see that the normalization was successful.</p>
<p>We can now split our data into training and test sets.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="knn.html#cb25-1"></a>trainDF_feat &lt;-<span class="st"> </span>cleanDF_n[<span class="dv">1</span><span class="op">:</span><span class="dv">469</span>,  ]</span>
<span id="cb25-2"><a href="knn.html#cb25-2"></a>testDF_feat &lt;-<span class="st"> </span>cleanDF_n[<span class="dv">470</span><span class="op">:</span><span class="dv">569</span>,  ]</span></code></pre></div>
<p>When creating the training and test sets, we’ve excluded the labels. We’ll create separate training and tests sets for them too.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="knn.html#cb26-1"></a>trainDF_labels &lt;-<span class="st"> </span>cleanDF[<span class="dv">1</span><span class="op">:</span><span class="dv">469</span>,  <span class="dv">1</span>]</span>
<span id="cb26-2"><a href="knn.html#cb26-2"></a>testDF_labels &lt;-<span class="st"> </span>cleanDF[<span class="dv">470</span><span class="op">:</span><span class="dv">569</span>,  <span class="dv">1</span>]</span></code></pre></div>
<p>Now we can train and evaluate our kNN model.</p>
</div>
<div id="modeling" class="section level2">
<h2><span class="header-section-number">2.4</span> Modeling</h2>
<p>To train the knn model we only need one single function from the <code>class</code> package. It takes the set with training features and the set with training label. The trained model is applied to the set with test features and the function gives back a set of predictions.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="knn.html#cb27-1"></a>cleanDF_test_pred &lt;-<span class="st"> </span><span class="kw">knn</span>(<span class="dt">train =</span> <span class="kw">as.matrix</span>(trainDF_feat), <span class="dt">test =</span> <span class="kw">as.matrix</span>(testDF_feat), <span class="dt">cl =</span> <span class="kw">as.matrix</span>(trainDF_labels), <span class="dt">k =</span> <span class="dv">21</span>)</span>
<span id="cb27-2"><a href="knn.html#cb27-2"></a><span class="kw">head</span>(cleanDF_test_pred)</span></code></pre></div>
<pre><code>## [1] Benign    Benign    Benign    Benign    Malignant Benign   
## Levels: Benign Malignant</code></pre>
</div>
<div id="evaluation" class="section level2">
<h2><span class="header-section-number">2.5</span> Evaluation</h2>
<p>Now that we have a set of predicted labels we can compare these with the actual labels. A diffusion table shows how well the model performed.</p>
<div class="figure" style="text-align: center"><span id="fig:difftable-fig"></span>
<img src="images/diffusion.png" alt="Standard diffusion table. Taken from: https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg" width="80%" />
<p class="caption">
Figure 2.1: Standard diffusion table. Taken from: <a href="https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg" class="uri">https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg</a>
</p>
</div>
<p>Here is our own table:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="knn.html#cb29-1"></a><span class="kw">confusionMatrix</span>(cleanDF_test_pred, testDF_labels[[<span class="dv">1</span>]], <span class="dt">positive =</span> <span class="ot">NULL</span>, <span class="dt">dnn =</span> <span class="kw">c</span>(<span class="st">&quot;Prediction&quot;</span>, <span class="st">&quot;True&quot;</span>))</span></code></pre></div>
<pre><code>## Warning in confusionMatrix.default(cleanDF_test_pred, testDF_labels[[1]], :
## Levels are not in the same order for reference and data. Refactoring data to
## match.</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##            True
## Prediction  Malignant Benign
##   Malignant        37      0
##   Benign            2     61
##                                           
##                Accuracy : 0.98            
##                  95% CI : (0.9296, 0.9976)
##     No Information Rate : 0.61            
##     P-Value [Acc &gt; NIR] : &lt;2e-16          
##                                           
##                   Kappa : 0.9576          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.4795          
##                                           
##             Sensitivity : 0.9487          
##             Specificity : 1.0000          
##          Pos Pred Value : 1.0000          
##          Neg Pred Value : 0.9683          
##              Prevalence : 0.3900          
##          Detection Rate : 0.3700          
##    Detection Prevalence : 0.3700          
##       Balanced Accuracy : 0.9744          
##                                           
##        &#39;Positive&#39; Class : Malignant       
## </code></pre>
<p><strong>Questions:</strong></p>
<ol style="list-style-type: decimal">
<li><em>How would you assess the overall performance of the model?</em></li>
<li><em>What would you consider as more costly: high false negatives or high false positives levels? Why?</em></li>
</ol>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-noauthor_uci_cancer_nodate">
<p>“UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set.” n.d. Accessed January 7, 2021. <a href="https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)">https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)</a>.</p>
</div>
<div id="ref-noauthor_who_nodate">
<p>“WHO Cancer Country Profiles 2020.” n.d. <em>WHO</em>. Accessed January 7, 2021. <a href="http://www.who.int/cancer/country-profiles/en/">http://www.who.int/cancer/country-profiles/en/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="dm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="naivebayes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["gitbook.pdf", "gitbook.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>

--- 
title: "Data Mining"
author: "Witek ten hove"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [lit.bib]
biblio-style: apalike
link-citations: yes
description: "This is a compagnon to the course Data Mining."
---

# Preface {-}

```{r title-fig, echo=FALSE, fig.align='center', fig.asp=.75, fig.cap='CRISP-DM Model taken from: https://commons.wikimedia.org/wiki/File:CRISP-DM_Process_Diagram.png', message=TRUE, warning=TRUE, out.width='80%'}
knitr::include_graphics(rep('images/crisp.png'))
```
## Prerequisites {-}

Before starting this module make sure you have:

* access to the book *Provost, F., & Fawcett, T. (2013). Data Science for Business: What you need to know about data mining and data-analytic thinking. O'Reilly Media, Inc.*
* installed R and RStudio
* a Github account

We will be using selected chapters from:

*[Lewis, N. D. C. (2016). Deep learning made easy with R: A gentle introduction for data science. AusCov.](https://drive.google.com/file/d/1p_PtuD6BGGTKTwNL9LUo9DEADWFskImK/view?usp=sharing)*

## Purpose of this course {-}

The general learning outcome of this course is:

> The student is able to perform a well-defined task independently in a relatively clearly arranged situation, or is able to perform in a complex and unpredictable situation under supervision.

The course will provide you with a few essential data mining skills. The focus will lie on non-linear modeling techniques - k-Nearest Neighbors (kNN) and Naive Bayes classification.

After a successful completion of the course, a student:

* is able to prepare data for a given non-linear model
* train en test a non-linear model
* evaluate the quality of a trained model

## Structure of the course {-}

```{r echo=FALSE, message=TRUE, warning=TRUE}
weeknr <- c("1", "2-3", "4-5", "6-7")
module <- c("Onboarding and Introduction to the Course", "Lazy Learning with kNN", "Probabilistic Kearning with Naive Bayes classification", "Neural Networks Basics")
reading <- c("Provost / Fawcett Ch.3", "Provost / Fawcett Ch.6 + 7", "Provost / Fawcett Ch.9", "Lewis")
headers <- c("Week nr.", "Module name", "Readings")
programmeDF <- data.frame(weeknr, module, reading)
colnames(programmeDF) <- headers

knitr::kable(
  programmeDF, longtable = TRUE, booktabs = TRUE,
  caption = 'Course overview'
)
```

The program has been divided into three blocks, each covering two weeks. During each block you'll be working individually on a case study. Through the whole of the program you'll be cooperating within a team where you will combine and compare the results of the different case studies. At the end of the course you will present with your team what you have learned from analyzing and comparing the different case studies.

# About the author {-}

![](images/me.png)

Witek ten Hove is a senior instructor and researcher at [HAN University of Applied Sciences](https://hanuniversity.com/en/). His main areas of expertise are Data en Web Technologies.

Through his extensive business experience in Finance and International Trade and thorough knowledge of modern data technologies, he is able to make connections between technology and business. As an open source evangelist he firmly believe in the power of knowledge sharing. His mission is to inspire business professionals and help them exploit the full potential of smart technologies.






<!--chapter:end:index.Rmd-->

```{r message=TRUE, warning=TRUE, include=FALSE}
library(tidyverse)
library(plotly)
```


# Introduction to Predictive Modeling {#dm}

```{r lesson-fig, echo=FALSE, fig.align='center', fig.asp=.75, fig.cap='Lesson Map taken from @provost_data_2013', message=TRUE, warning=TRUE, out.width='80%'}
knitr::include_graphics('images/lesson.png')
```

<!--chapter:end:01-introduction-predictive-modeling.Rmd-->

# Lazy learning with k-Nearest Neighbors  {#knn}

<iframe width="560" height="315" src="https://www.youtube.com/embed/MDniRwXizWo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(googlesheets4)
library(class)
library(caret)
```

## Business Case: Diagnosing Breast Cancer

Breast cancer is the top cancer in women both in the developed and the developing world. In the Netherlands it is the most pervasive form of cancer [@noauthor_who_nodate]. In order to improve breast cancer outcome and survival early detection remains the most important instrument for breast cancer control. If machine learning could automate the identification of cancer, it would improve efficiency of the detection process and might also increase its effectiveness by providing greater detection accuracy.

## Data Understanding
The data we will be using comes from the University of Wisconsin and is available online as an open source dataset [@noauthor_uci_nodate]. It includes measurements from digitized images from from fine-needle aspirates of breast mass. The values represent cell nuclei features.

The data is saved online as a Google Spreadsheet. We can access it directly using a function dedicated to reading Google Spreadsheets from the `googlesheets4` package.

```{r}
gs4_deauth()
rawDF <- read_sheet("https://docs.google.com/spreadsheets/d/1vnrj4nylo1X_yM3DBi-oQhBb2Cb2eVlbOdyWsxiqI9g/edit?usp=sharing")
```

Using the `str()` function we can have some basic information about the dataset.

```{r}
str(rawDF)
```

The dataset has `r dim(rawDF)[2]` variables (columns) and `r dim(rawDF)[1]` observations (rows). 

## Preparation
The first variable, `id`, contains unique patient IDs. The IDs do not contain any relevant information for making predictions, so we will delete it from the dataset.

```{r}
cleanDF <- rawDF[-1]
head(cleanDF)
```
The variable named `diagnosis` contains the outcomes we would like to predict - 'B' for 'Benign' and 'M' for 'Malignant'. The variable we would like to predict is called the 'label'. We can look at the counts and proportions for both outcomes, using the `tables()` and `prop.tables()`functions.

```{r}
cntDiag <- table(cleanDF$diagnosis)
propDiag <- round(prop.table(cntDiag) * 100 , digits = 1)

cntDiag
propDiag
```

The variable is now coded as a type `character`. Many models require that the label is of type `factor`. This is easily solved using the `factor()` function.

```{r}
cleanDF$diagnosis <- factor(cleanDF$diagnosis, levels = c("B", "M"), labels = c("Benign", "Malignant")) %>% relevel("Malignant")
head(cleanDF, 10)
```
The features consist of three different measurements of ten characteristics. We will take three characteristics and have a closer look.

```{r}
summary(cleanDF[c("radius_mean", "area_mean", "smoothness_mean")])
```

You'll notice that the three variables have very different ranges and as a consequence `area_mean` will have a larger impact on the distance calculation than the `smootness_mean`. This could potentially cause problems for modeling. To solve this we'll apply normalization to rescale all features to a standard range of values.

We will write our own normalization function.

```{r}
normalize <- function(x) { # Function takes in a vector
  return ((x - min(x)) / (max(x) - min(x))) # distance of item value - minimum vector value divided by the range of all vector values
}

testSet1 <- c(1:5)
testSet2 <- c(1:5) * 10

cat("testSet1:", testSet1, "\n")
cat("testSet2:", testSet2, "\n")

cat("Normalized testSet1:", normalize(testSet1), "\n")
cat("Normalized testSet2:", normalize(testSet2))
```

We'll apply the `normalize()` function to each feature in the dataset (so, not on the label) using the `sapply()` function.

```{r}
nCols <- dim(cleanDF)[2]
cleanDF_n <- sapply(2:nCols,
                    function(x) {
  normalize(cleanDF[,x])
}) %>% as.data.frame()

summary(cleanDF_n[c("radius_mean", "area_mean", "smoothness_mean")])
```

When we take the variables we selected earlier and look at the summary parameters again, we'll see that the normalization was successful.

We can now split our data into training and test sets.

```{r}
trainDF_feat <- cleanDF_n[1:469,  ]
testDF_feat <- cleanDF_n[470:569,  ]
```

When creating the training and test sets, we've excluded the labels. We'll create separate training and tests sets for them too.

```{r}
trainDF_labels <- cleanDF[1:469,  1]
testDF_labels <- cleanDF[470:569,  1]
```

Now we can train and evaluate our kNN model.

## Modeling

To train the knn model we only need one single function from the `class` package. It takes the set with training features and the set with training label. The trained model is applied to the set with test features and the function gives back a set of predictions.

```{r}
cleanDF_test_pred <- knn(train = as.matrix(trainDF_feat), test = as.matrix(testDF_feat), cl = as.matrix(trainDF_labels), k = 21)
head(cleanDF_test_pred)
```

## Evaluation

Now that we have a set of predicted labels we can compare these with the actual labels. A diffusion table shows how well the model performed.

```{r difftable-fig, echo=FALSE, fig.align='center', fig.asp=.75, fig.cap='Standard diffusion table. Taken from: https://emj.bmj.com/content/emermed/36/7/431/F1.large.jpg', message=TRUE, warning=TRUE, out.width='80%'}
knitr::include_graphics(rep('images/diffusion.png'))
```

Here is our own table:
```{r}
confusionMatrix(cleanDF_test_pred, testDF_labels[[1]], positive = NULL, dnn = c("Prediction", "True"))

```

*Questions:* 

1. How accurate is our model?
2. How high is the False Negative rate?
3. What would you assume as more costly a high False Negatives or high False Positives and why?


<!--chapter:end:02-k-nearest-neighbors.Rmd-->

# Probabilistic Learning with Naive Bayes Classification {#naivebayes}


<!--chapter:end:03-naive-bayes.Rmd-->

# Neural Networks Basics {#neuralnets}


<!--chapter:end:04-neural-nets.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:05-references.Rmd-->

